"""
Sentiment Analysis Service - Production Grade v1.0
ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤

Features:
- í•œêµ­ì–´/ì˜ì–´ ê°ì • ë¶„ì„
- ë‹¤ì¤‘ ë ˆì´ë¸” ì§€ì› (positive, negative, neutral, mixed)
- ê°ì • ê°•ë„ ì ìˆ˜í™”
- í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ë¶„ì„ + LLM ê¸°ë°˜ ì •ë°€ ë¶„ì„
- ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›

Author: ONTIX Universal Team
"""

from dataclasses import dataclass, field
from enum import Enum
from typing import List, Dict, Any, Optional, Tuple
import re
import logging

logger = logging.getLogger(__name__)


# ============================================================
# Enums and Data Classes
# ============================================================

class SentimentLabel(str, Enum):
    """ê°ì • ë ˆì´ë¸”"""
    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"
    MIXED = "mixed"


class AnalysisMode(str, Enum):
    """ë¶„ì„ ëª¨ë“œ"""
    FAST = "fast"          # í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ë¶„ì„
    ACCURATE = "accurate"  # LLM ê¸°ë°˜ ì •ë°€ ë¶„ì„
    AUTO = "auto"          # ìë™ ì„ íƒ


@dataclass
class SentimentScore:
    """ê°œë³„ ê°ì • ì ìˆ˜"""
    positive: float = 0.0
    negative: float = 0.0
    neutral: float = 0.0

    def dominant(self) -> SentimentLabel:
        """ì§€ë°°ì ì¸ ê°ì • ë°˜í™˜"""
        scores = {
            SentimentLabel.POSITIVE: self.positive,
            SentimentLabel.NEGATIVE: self.negative,
            SentimentLabel.NEUTRAL: self.neutral,
        }

        # í˜¼í•© ê°ì • ê°ì§€ (positiveì™€ negativeê°€ ëª¨ë‘ ë†’ìŒ)
        if self.positive > 0.3 and self.negative > 0.3:
            return SentimentLabel.MIXED

        return max(scores, key=scores.get)

    def confidence(self) -> float:
        """í™•ì‹ ë„ (ê°€ì¥ ë†’ì€ ì ìˆ˜)"""
        return max(self.positive, self.negative, self.neutral)


@dataclass
class SentimentResult:
    """ê°ì • ë¶„ì„ ê²°ê³¼"""
    label: SentimentLabel
    score: SentimentScore
    confidence: float
    keywords_found: List[str] = field(default_factory=list)
    analysis_mode: AnalysisMode = AnalysisMode.FAST

    # ìƒì„¸ ë¶„ì„ ê²°ê³¼ (LLM ë¶„ì„ ì‹œ)
    explanation: Optional[str] = None
    aspects: Dict[str, SentimentLabel] = field(default_factory=dict)  # ì¸¡ë©´ë³„ ê°ì •

    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "label": self.label.value,
            "score": {
                "positive": round(self.score.positive, 3),
                "negative": round(self.score.negative, 3),
                "neutral": round(self.score.neutral, 3),
            },
            "confidence": round(self.confidence, 3),
            "keywords_found": self.keywords_found,
            "analysis_mode": self.analysis_mode.value,
            "explanation": self.explanation,
            "aspects": {k: v.value for k, v in self.aspects.items()} if self.aspects else {},
        }


@dataclass
class SentimentConfig:
    """ê°ì • ë¶„ì„ ì„¤ì •"""
    # ë¶„ì„ ëª¨ë“œ
    mode: AnalysisMode = AnalysisMode.AUTO

    # ì–¸ì–´ ì„¤ì •
    language: str = "ko"  # ko, en, auto

    # ì„ê³„ê°’
    positive_threshold: float = 0.6
    negative_threshold: float = 0.6
    mixed_threshold: float = 0.3

    # LLM ì„¤ì • (accurate ëª¨ë“œ)
    use_llm_for_ambiguous: bool = True
    llm_model: str = "gpt-5-mini"

    # ë°°ì¹˜ ì„¤ì •
    batch_size: int = 10

    # í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜
    keyword_weight: float = 0.4
    pattern_weight: float = 0.3
    length_weight: float = 0.1
    context_weight: float = 0.2


# ============================================================
# Sentiment Analyzer
# ============================================================

class SentimentAnalyzer:
    """
    ê°ì • ë¶„ì„ê¸°

    í•œêµ­ì–´ì™€ ì˜ì–´ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    ë¹ ë¥¸ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ê³¼ ì •ë°€í•œ LLM ê¸°ë°˜ ë¶„ì„ì„ ì§€ì›í•©ë‹ˆë‹¤.
    """

    # í•œêµ­ì–´ ê°ì • í‚¤ì›Œë“œ
    KOREAN_POSITIVE_KEYWORDS = [
        # ê¸°ì¨/ë§Œì¡±
        "ì¢‹ì•„", "ì¢‹ë‹¤", "ì¢‹ë„¤", "ì¢‹ìŠµë‹ˆë‹¤", "ì¢‹ìŒ", "ìµœê³ ", "ëŒ€ë°•", "ì§±",
        "ì™„ë²½", "í›Œë¥­", "ë©‹ì§€", "ë©‹ì§„", "ë©‹ìˆ", "ì˜ˆì˜", "ì´ì˜", "ê·€ì—½",
        "ì‚¬ë‘", "ê°ì‚¬", "ê³ ë§ˆ", "ì¶•í•˜", "í–‰ë³µ", "ê¸°ë»", "ì¦ê±°", "ì‹ ë‚˜",
        "ì¶”ì²œ", "ê°•ì¶”", "ì¸ì •", "êµ¿", "ë² ìŠ¤íŠ¸", "ë§Œì¡±", "ê°ë™", "íë§",
        # ê¸ì • í‘œí˜„
        "ã…ã…", "ã…‹ã…‹", "ã… ã… ", "â™¥", "â¤", "ğŸ‘", "ğŸ˜Š", "ğŸ¥°", "ğŸ˜",
    ]

    KOREAN_NEGATIVE_KEYWORDS = [
        # ë¶ˆë§Œ/ë¶€ì •
        "ì‹«ì–´", "ì‹«ë‹¤", "ì‹«ìŒ", "ë³„ë¡œ", "ìµœì•…", "ì“°ë ˆê¸°", "ë§", "ë…¸ë‹µ",
        "ì‹¤ë§", "í›„íšŒ", "ì§œì¦", "í™”ë‚˜", "ì—´ë°›", "ë¹¡ì¹˜", "ì–´ì´ì—†", "í™©ë‹¹",
        "ë¶ˆë§Œ", "ë¶ˆí¸", "ì•„ì‰¬", "ì•ˆì¢‹", "ì•ˆ ì¢‹", "ë¹„ì¶”", "ë…¸ë…¸", "ë³„ì ",
        "í™˜ë¶ˆ", "ì·¨ì†Œ", "ë°˜í’ˆ", "ë¬¸ì œ", "ê³ ì¥", "í•˜ì", "ë¶ˆëŸ‰",
        # ë¶€ì • í‘œí˜„
        "ã…¡ã…¡", "ã… ã… ", "ğŸ˜¢", "ğŸ˜­", "ğŸ˜¡", "ğŸ˜¤", "ğŸ‘",
    ]

    KOREAN_NEUTRAL_PATTERNS = [
        r'^(ì§ˆë¬¸|ë¬¸ì˜|ê¶ê¸ˆ|ì–´ë–»ê²Œ|ë­|ì–¸ì œ|ì–´ë””|ì™œ)',
        r'(ì…ë‹ˆë‹¤|í•©ë‹ˆë‹¤|ë©ë‹ˆë‹¤|ìˆìŠµë‹ˆë‹¤)$',
        r'^(ì•ˆë…•|ë°˜ê°‘)',
    ]

    # ì˜ì–´ ê°ì • í‚¤ì›Œë“œ
    ENGLISH_POSITIVE_KEYWORDS = [
        "love", "great", "amazing", "awesome", "excellent", "perfect",
        "best", "good", "nice", "wonderful", "fantastic", "beautiful",
        "recommend", "happy", "enjoy", "thanks", "thank", "appreciate",
    ]

    ENGLISH_NEGATIVE_KEYWORDS = [
        "hate", "bad", "terrible", "awful", "horrible", "worst",
        "disappointed", "disappointed", "angry", "upset", "sad",
        "refund", "return", "cancel", "broken", "defect", "problem",
        "poor", "waste", "scam", "fraud", "fake",
    ]

    def __init__(self, config: Optional[SentimentConfig] = None):
        """
        ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™”

        Args:
            config: ë¶„ì„ ì„¤ì •
        """
        self.config = config or SentimentConfig()
        self._llm_client = None

        logger.info(
            f"[SentimentAnalyzer] Initialized "
            f"(mode={self.config.mode.value}, language={self.config.language})"
        )

    @property
    def llm_client(self):
        """LLM í´ë¼ì´ì–¸íŠ¸ ì§€ì—° ë¡œë”©"""
        if self._llm_client is None:
            try:
                from app.services.shared.llm import get_llm_client
                self._llm_client = get_llm_client()
            except Exception as e:
                logger.warning(f"[SentimentAnalyzer] LLM client unavailable: {e}")
        return self._llm_client

    def analyze(self, text: str, context: Optional[Dict[str, Any]] = None) -> SentimentResult:
        """
        ë‹¨ì¼ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„

        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (optional)

        Returns:
            SentimentResult: ê°ì • ë¶„ì„ ê²°ê³¼
        """
        if not text or not text.strip():
            return SentimentResult(
                label=SentimentLabel.NEUTRAL,
                score=SentimentScore(neutral=1.0),
                confidence=1.0,
                analysis_mode=AnalysisMode.FAST,
            )

        # ì–¸ì–´ ê°ì§€
        language = self._detect_language(text) if self.config.language == "auto" else self.config.language

        # ë¶„ì„ ëª¨ë“œ ê²°ì •
        mode = self.config.mode
        if mode == AnalysisMode.AUTO:
            mode = self._determine_analysis_mode(text)

        # ë¶„ì„ ì‹¤í–‰
        if mode == AnalysisMode.FAST:
            return self._analyze_fast(text, language)
        else:
            return self._analyze_accurate(text, language, context)

    def analyze_batch(self, texts: List[str], context: Optional[Dict[str, Any]] = None) -> List[SentimentResult]:
        """
        ë°°ì¹˜ ê°ì • ë¶„ì„

        Args:
            texts: ë¶„ì„í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸

        Returns:
            List[SentimentResult]: ê°ì • ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []

        for i in range(0, len(texts), self.config.batch_size):
            batch = texts[i:i + self.config.batch_size]
            batch_results = [self.analyze(text, context) for text in batch]
            results.extend(batch_results)

        return results

    def analyze_with_aspects(
        self,
        text: str,
        aspects: List[str],
        context: Optional[Dict[str, Any]] = None
    ) -> SentimentResult:
        """
        ì¸¡ë©´ë³„ ê°ì • ë¶„ì„ (Aspect-based Sentiment Analysis)

        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            aspects: ë¶„ì„í•  ì¸¡ë©´ë“¤ (ì˜ˆ: ['í’ˆì§ˆ', 'ê°€ê²©', 'ë°°ì†¡'])
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸

        Returns:
            SentimentResult: ì¸¡ë©´ë³„ ê°ì •ì´ í¬í•¨ëœ ë¶„ì„ ê²°ê³¼
        """
        # ê¸°ë³¸ ë¶„ì„
        base_result = self.analyze(text, context)

        # ì¸¡ë©´ë³„ ë¶„ì„
        aspect_sentiments = {}
        for aspect in aspects:
            aspect_score = self._analyze_aspect(text, aspect)
            aspect_sentiments[aspect] = aspect_score.dominant()

        base_result.aspects = aspect_sentiments
        return base_result

    def get_summary(self, results: List[SentimentResult]) -> Dict[str, Any]:
        """
        ë¶„ì„ ê²°ê³¼ ìš”ì•½

        Args:
            results: ê°ì • ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

        Returns:
            ìš”ì•½ í†µê³„
        """
        if not results:
            return {
                "total": 0,
                "distribution": {},
                "average_confidence": 0,
                "average_scores": {
                    "positive": 0,
                    "negative": 0,
                    "neutral": 0,
                }
            }

        # ë ˆì´ë¸”ë³„ ë¶„í¬
        distribution = {label: 0 for label in SentimentLabel}
        total_positive = 0
        total_negative = 0
        total_neutral = 0
        total_confidence = 0

        for result in results:
            distribution[result.label] += 1
            total_positive += result.score.positive
            total_negative += result.score.negative
            total_neutral += result.score.neutral
            total_confidence += result.confidence

        count = len(results)

        return {
            "total": count,
            "distribution": {label.value: count for label, count in distribution.items()},
            "distribution_percent": {
                label.value: round(count / len(results) * 100, 1)
                for label, count in distribution.items()
            },
            "average_confidence": round(total_confidence / count, 3),
            "average_scores": {
                "positive": round(total_positive / count, 3),
                "negative": round(total_negative / count, 3),
                "neutral": round(total_neutral / count, 3),
            },
            "dominant_sentiment": max(distribution, key=distribution.get).value,
        }

    # ============================================================
    # Private Methods
    # ============================================================

    def _detect_language(self, text: str) -> str:
        """ì–¸ì–´ ê°ì§€"""
        # ê°„ë‹¨í•œ í•œêµ­ì–´/ì˜ì–´ ê°ì§€
        korean_chars = len(re.findall(r'[ê°€-í£]', text))
        english_chars = len(re.findall(r'[a-zA-Z]', text))

        if korean_chars > english_chars:
            return "ko"
        elif english_chars > korean_chars:
            return "en"
        else:
            return self.config.language  # ê¸°ë³¸ê°’ ì‚¬ìš©

    def _determine_analysis_mode(self, text: str) -> AnalysisMode:
        """ìë™ ë¶„ì„ ëª¨ë“œ ê²°ì •"""
        # ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ë¹ ë¥¸ ë¶„ì„
        if len(text) < 50:
            return AnalysisMode.FAST

        # ê¸´ í…ìŠ¤íŠ¸ë‚˜ ë³µì¡í•œ ë¬¸ì¥ì€ ì •ë°€ ë¶„ì„
        if len(text) > 200 or text.count('.') > 3:
            return AnalysisMode.ACCURATE

        return AnalysisMode.FAST

    def _analyze_fast(self, text: str, language: str) -> SentimentResult:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ë¶„ì„"""
        text_lower = text.lower()

        # ì–¸ì–´ë³„ í‚¤ì›Œë“œ ì„ íƒ
        if language == "ko":
            positive_keywords = self.KOREAN_POSITIVE_KEYWORDS
            negative_keywords = self.KOREAN_NEGATIVE_KEYWORDS
            neutral_patterns = self.KOREAN_NEUTRAL_PATTERNS
        else:
            positive_keywords = self.ENGLISH_POSITIVE_KEYWORDS
            negative_keywords = self.ENGLISH_NEGATIVE_KEYWORDS
            neutral_patterns = []

        # í‚¤ì›Œë“œ ë§¤ì¹­
        found_positive = [kw for kw in positive_keywords if kw in text_lower]
        found_negative = [kw for kw in negative_keywords if kw in text_lower]

        # ì¤‘ë¦½ íŒ¨í„´ í™•ì¸
        is_neutral_pattern = any(
            re.search(pattern, text_lower) for pattern in neutral_patterns
        )

        # ì ìˆ˜ ê³„ì‚°
        pos_count = len(found_positive)
        neg_count = len(found_negative)
        total = pos_count + neg_count + 1  # +1 for smoothing

        if is_neutral_pattern and pos_count == 0 and neg_count == 0:
            score = SentimentScore(neutral=1.0)
        else:
            positive_score = pos_count / total
            negative_score = neg_count / total
            neutral_score = 1.0 - positive_score - negative_score

            # ì •ê·œí™”
            total_score = positive_score + negative_score + neutral_score
            score = SentimentScore(
                positive=positive_score / total_score,
                negative=negative_score / total_score,
                neutral=max(0, neutral_score / total_score),
            )

        # í™•ì‹ ë„ ê³„ì‚°
        confidence = score.confidence()
        if pos_count == 0 and neg_count == 0:
            confidence = 0.5  # í‚¤ì›Œë“œ ì—†ìœ¼ë©´ ë‚®ì€ í™•ì‹ ë„

        return SentimentResult(
            label=score.dominant(),
            score=score,
            confidence=confidence,
            keywords_found=found_positive + found_negative,
            analysis_mode=AnalysisMode.FAST,
        )

    def _analyze_accurate(
        self,
        text: str,
        language: str,
        context: Optional[Dict[str, Any]] = None
    ) -> SentimentResult:
        """LLM ê¸°ë°˜ ì •ë°€ ë¶„ì„"""
        # LLMì´ ì—†ìœ¼ë©´ ë¹ ë¥¸ ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´
        if not self.llm_client:
            logger.warning("[SentimentAnalyzer] LLM unavailable, falling back to fast mode")
            return self._analyze_fast(text, language)

        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_sentiment_prompt(text, language, context)

            # LLM í˜¸ì¶œ
            # GPT-5 ëª¨ë¸ì€ temperature/top_p íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ
            llm_params = {
                "model": self.config.llm_model,
                "messages": [
                    {"role": "system", "content": "You are a sentiment analysis expert."},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 200,
            }

            # GPT-5 ê³„ì—´ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ temperature ì¶”ê°€
            if not self.config.llm_model.startswith("gpt-5"):
                llm_params["temperature"] = 0.1

            response = self.llm_client.chat.completions.create(**llm_params)

            # ì‘ë‹µ íŒŒì‹±
            result_text = response.choices[0].message.content
            return self._parse_llm_response(result_text)

        except Exception as e:
            logger.error(f"[SentimentAnalyzer] LLM analysis failed: {e}")
            return self._analyze_fast(text, language)

    def _build_sentiment_prompt(
        self,
        text: str,
        language: str,
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """LLM ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        lang_instruction = "í•œêµ­ì–´ë¡œ" if language == "ko" else "in English"

        prompt = f"""Analyze the sentiment of the following text {lang_instruction}.

Text: "{text}"

Respond in JSON format:
{{
    "label": "positive" | "negative" | "neutral" | "mixed",
    "confidence": 0.0-1.0,
    "positive_score": 0.0-1.0,
    "negative_score": 0.0-1.0,
    "neutral_score": 0.0-1.0,
    "explanation": "brief explanation"
}}

Only output the JSON, nothing else."""

        return prompt

    def _parse_llm_response(self, response: str) -> SentimentResult:
        """LLM ì‘ë‹µ íŒŒì‹±"""
        import json

        try:
            # JSON ì¶”ì¶œ
            json_match = re.search(r'\{[^}]+\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())

                label_map = {
                    "positive": SentimentLabel.POSITIVE,
                    "negative": SentimentLabel.NEGATIVE,
                    "neutral": SentimentLabel.NEUTRAL,
                    "mixed": SentimentLabel.MIXED,
                }

                return SentimentResult(
                    label=label_map.get(data.get("label", "neutral"), SentimentLabel.NEUTRAL),
                    score=SentimentScore(
                        positive=data.get("positive_score", 0),
                        negative=data.get("negative_score", 0),
                        neutral=data.get("neutral_score", 0),
                    ),
                    confidence=data.get("confidence", 0.5),
                    analysis_mode=AnalysisMode.ACCURATE,
                    explanation=data.get("explanation"),
                )
        except (json.JSONDecodeError, KeyError) as e:
            logger.warning(f"[SentimentAnalyzer] Failed to parse LLM response: {e}")

        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
        return SentimentResult(
            label=SentimentLabel.NEUTRAL,
            score=SentimentScore(neutral=1.0),
            confidence=0.3,
            analysis_mode=AnalysisMode.ACCURATE,
        )

    def _analyze_aspect(self, text: str, aspect: str) -> SentimentScore:
        """íŠ¹ì • ì¸¡ë©´ì— ëŒ€í•œ ê°ì • ë¶„ì„"""
        # ì¸¡ë©´ ê´€ë ¨ ë¬¸ì¥ ì¶”ì¶œ
        sentences = re.split(r'[.!?]', text)
        relevant_sentences = [s for s in sentences if aspect.lower() in s.lower()]

        if not relevant_sentences:
            return SentimentScore(neutral=1.0)

        # ê´€ë ¨ ë¬¸ì¥ë“¤ì˜ ê°ì • ë¶„ì„
        combined_text = ' '.join(relevant_sentences)
        result = self._analyze_fast(combined_text, self._detect_language(text))

        return result.score
