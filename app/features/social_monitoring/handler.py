"""
Social Monitoring Handler - Production Grade v2.0
ì†Œì…œ ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥

Features:
- Filters v2.0 í†µí•© (Quality + Trust)
- ì‹¤ì‹œê°„ ì†Œì…œ ë¯¸ë””ì–´ ëª¨ë‹ˆí„°ë§
- ë©˜ì…˜/í•´ì‹œíƒœê·¸ ì¶”ì 
- ìƒì„¸ ë©”íŠ¸ë¦­ ë¡œê¹…
"""

from app.models.feature import FeatureHandler
from app.filters import (
    QualityFilter,
    TrustFilter,
    QualityConfig,
    TrustConfig,
    QualityResult,
    TrustResult,
)
from app.filters.relevance import (
    RelevanceFilter,
    RelevanceConfig,
    RelevanceResult,
    RelevanceLevel,
)
from app.filters.validation import (
    ValidationFilter,
    ValidationConfig,
    ValidationResult,
    ValidationStatus,
    OverallGrade,
    FilterWeight,
)
from app.services.analysis.sentiment import (
    SentimentAnalyzer,
    SentimentConfig,
    SentimentResult,
    SentimentLabel,
    AnalysisMode,
)
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


# ============================================================
# Configuration
# ============================================================

@dataclass
class SocialMonitoringConfig:
    """ì†Œì…œ ëª¨ë‹ˆí„°ë§ ì„¤ì •"""
    # í•„í„° í™œì„±í™”
    quality_filter_enabled: bool = True
    trust_filter_enabled: bool = True
    relevance_filter_enabled: bool = True
    validation_filter_enabled: bool = True

    # í’ˆì§ˆ ì„ê³„ê°’
    min_quality_score: float = 0.5
    min_trust_score: float = 0.5
    min_relevance_score: float = 0.5

    # ì¢…í•© ê²€ì¦ ì„ê³„ê°’
    validation_pass_threshold: float = 0.7
    validation_warning_threshold: float = 0.5

    # ëª¨ë‹ˆí„°ë§ ì„¤ì •
    platforms: List[str] = None
    track_mentions: bool = True
    track_hashtags: bool = True
    max_results: int = 20

    # ê°ì • ë¶„ì„ ì„¤ì •
    sentiment_analysis_enabled: bool = True
    sentiment_analysis_mode: str = "auto"  # fast, accurate, auto

    # ë¡œê¹…
    log_filter_results: bool = True
    log_monitoring: bool = True

    # ë©”íƒ€ë°ì´í„°
    include_quality_details: bool = True
    include_trust_details: bool = True
    include_relevance_details: bool = True
    include_validation_details: bool = True
    include_sentiment_details: bool = True

    def __post_init__(self):
        if self.platforms is None:
            self.platforms = ['instagram', 'twitter', 'youtube', 'tiktok']


# ============================================================
# Social Monitoring Handler
# ============================================================

class SocialMonitoringHandler(FeatureHandler):
    """
    ì†Œì…œ ëª¨ë‹ˆí„°ë§ í•¸ë“¤ëŸ¬ - Production Grade v2.0

    Features:
    - ë©€í‹° í”Œë«í¼ ëª¨ë‹ˆí„°ë§
    - ë©˜ì…˜/í•´ì‹œíƒœê·¸ ì¶”ì 
    - ëª¨ë‹ˆí„°ë§ ê²°ê³¼ í’ˆì§ˆ ê²€ì¦
    - ì‹¤ì‹œê°„ ì•Œë¦¼
    """

    def __init__(self, brand_config: Dict[str, Any]):
        super().__init__(brand_config)

        # ì„¤ì • ë¡œë“œ
        config_dict = brand_config.get('social_monitoring', {})
        self.handler_config = SocialMonitoringConfig(
            quality_filter_enabled=config_dict.get('quality_filter_enabled', True),
            trust_filter_enabled=config_dict.get('trust_filter_enabled', True),
            relevance_filter_enabled=config_dict.get('relevance_filter_enabled', True),
            validation_filter_enabled=config_dict.get('validation_filter_enabled', True),
            min_quality_score=config_dict.get('min_quality_score', 0.5),
            min_trust_score=config_dict.get('min_trust_score', 0.5),
            min_relevance_score=config_dict.get('min_relevance_score', 0.5),
            validation_pass_threshold=config_dict.get('validation_pass_threshold', 0.7),
            validation_warning_threshold=config_dict.get('validation_warning_threshold', 0.5),
            platforms=config_dict.get('platforms', ['instagram', 'twitter', 'youtube', 'tiktok']),
            track_mentions=config_dict.get('track_mentions', True),
            track_hashtags=config_dict.get('track_hashtags', True),
            max_results=config_dict.get('max_results', 20),
            sentiment_analysis_enabled=config_dict.get('sentiment_analysis_enabled', True),
            sentiment_analysis_mode=config_dict.get('sentiment_analysis_mode', 'auto'),
            log_filter_results=config_dict.get('log_filter_results', True),
            log_monitoring=config_dict.get('log_monitoring', True),
            include_quality_details=config_dict.get('include_quality_details', True),
            include_trust_details=config_dict.get('include_trust_details', True),
            include_relevance_details=config_dict.get('include_relevance_details', True),
            include_validation_details=config_dict.get('include_validation_details', True),
            include_sentiment_details=config_dict.get('include_sentiment_details', True),
        )

        # Filters v2.0 ì´ˆê¸°í™”
        self.quality_filter = QualityFilter(
            config=QualityConfig(
                language="ko",
                min_length=50,
                optimal_min_length=150,
            )
        )
        self.trust_filter = TrustFilter(
            config=TrustConfig(
                min_trust_score=self.handler_config.min_trust_score,
            )
        )
        self.relevance_filter = RelevanceFilter(
            config=RelevanceConfig(
                min_relevance_score=self.handler_config.min_relevance_score,
            )
        )
        self.validation_filter = ValidationFilter(
            config=ValidationConfig(
                trust_config=TrustConfig(
                    min_trust_score=self.handler_config.min_trust_score,
                ),
                quality_config=QualityConfig(
                    language="ko",
                    min_length=50,
                ),
                relevance_config=RelevanceConfig(
                    min_relevance_score=self.handler_config.min_relevance_score,
                ),
                min_pass_score=self.handler_config.validation_pass_threshold,
                warning_threshold=self.handler_config.validation_warning_threshold,
            )
        )

        # ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™”
        mode_map = {
            'fast': AnalysisMode.FAST,
            'accurate': AnalysisMode.ACCURATE,
            'auto': AnalysisMode.AUTO,
        }
        self.sentiment_analyzer = SentimentAnalyzer(
            config=SentimentConfig(
                mode=mode_map.get(self.handler_config.sentiment_analysis_mode, AnalysisMode.AUTO),
                language="ko",
            )
        )

        logger.info(
            f"[SocialMonitoringHandler] Initialized for {self.brand_id} "
            f"(Quality={self.handler_config.quality_filter_enabled}, "
            f"Trust={self.handler_config.trust_filter_enabled}, "
            f"Relevance={self.handler_config.relevance_filter_enabled}, "
            f"Validation={self.handler_config.validation_filter_enabled}, "
            f"Sentiment={self.handler_config.sentiment_analysis_enabled})"
        )

    def _extract_feature_config(self) -> Dict[str, Any]:
        return self.brand_config.get('social_monitoring', {})

    def can_handle(self, question: str, context: Dict[str, Any]) -> bool:
        """ì†Œì…œ ëª¨ë‹ˆí„°ë§ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ íŒë‹¨"""
        keywords = [
            'ëª¨ë‹ˆí„°ë§', 'ì¶”ì ', 'ê°ì‹œ', 'ì†Œì…œ', 'sns',
            'ë©˜ì…˜', 'í•´ì‹œíƒœê·¸', 'ì–¸ê¸‰', 'ë°˜ì‘', 'ëŒ“ê¸€',
            'ì¸ìŠ¤íƒ€', 'íŠ¸ìœ„í„°', 'ìœ íŠœë¸Œ', 'í‹±í†¡',
        ]
        question_lower = question.lower()

        return any(kw in question_lower for kw in keywords)

    def process(self, question: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì†Œì…œ ëª¨ë‹ˆí„°ë§ ì²˜ë¦¬ ë° í’ˆì§ˆ ê²€ì¦

        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            context: ì»¨í…ìŠ¤íŠ¸

        Returns:
            ì²˜ë¦¬ ê²°ê³¼ (response, metadata, filter_results)
        """
        start_time = datetime.now()

        # ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™”
        metadata = {
            'handled_by': 'social_monitoring',
            'handler_version': '2.0',
            'processed_at': start_time.isoformat(),
            'monitoring_type': self._detect_monitoring_type(question),
            'platforms': self.handler_config.platforms,
        }

        # ê²€ì¦ ê²°ê³¼ ì €ì¥ì†Œ
        filter_results = {
            'quality': None,
            'trust': None,
            'relevance': None,
            'validation': None,
        }
        all_suggestions: List[str] = []

        try:
            # ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì¡°íšŒ
            monitoring_data = self._fetch_monitoring_data(question)
            metadata['data_count'] = len(monitoring_data.get('items', []))

            # ì‘ë‹µ ìƒì„±
            if monitoring_data.get('items'):
                response = self._format_monitoring_results(monitoring_data)

                if self.handler_config.log_monitoring:
                    logger.info(
                        f"[SocialMonitoringHandler] Found {len(monitoring_data['items'])} items "
                        f"for: {question[:50]}..."
                    )
            else:
                response = self._generate_no_data_response()

            # === Quality Filter ì ìš© ===
            if self.handler_config.quality_filter_enabled and response:
                quality_result = self._apply_quality_filter(response, context)
                filter_results['quality'] = quality_result

                if quality_result:
                    all_suggestions.extend(quality_result.get('suggestions', []))

                    if self.handler_config.include_quality_details:
                        metadata['quality'] = {
                            'score': quality_result.get('score'),
                            'level': quality_result.get('level'),
                            'valid': quality_result.get('valid'),
                        }

            # === Trust Filter ì ìš© ===
            if self.handler_config.trust_filter_enabled and response:
                trust_context = {
                    **context,
                    'retrieval_results': monitoring_data,
                }
                trust_result = self._apply_trust_filter(response, question, trust_context)
                filter_results['trust'] = trust_result

                if trust_result:
                    if self.handler_config.include_trust_details:
                        metadata['trust'] = {
                            'score': trust_result.get('score'),
                            'level': trust_result.get('level'),
                            'hallucination_risk': trust_result.get('hallucination_risk'),
                            'valid': trust_result.get('valid'),
                        }

            # === Relevance Filter ì ìš© ===
            if self.handler_config.relevance_filter_enabled and response:
                relevance_result = self._apply_relevance_filter(response, question, context)
                filter_results['relevance'] = relevance_result

                if relevance_result:
                    if self.handler_config.include_relevance_details:
                        metadata['relevance'] = {
                            'score': relevance_result.get('score'),
                            'level': relevance_result.get('level'),
                            'response_type': relevance_result.get('response_type'),
                            'valid': relevance_result.get('valid'),
                        }

            # === Validation Filter ì ìš© (ì¢…í•© ê²€ì¦) ===
            if self.handler_config.validation_filter_enabled and response:
                validation_result = self._apply_validation_filter(response, question, context)
                filter_results['validation'] = validation_result

                if validation_result:
                    all_suggestions.extend(validation_result.get('suggestions', []))

                    if self.handler_config.include_validation_details:
                        metadata['validation'] = {
                            'score': validation_result.get('score'),
                            'grade': validation_result.get('grade'),
                            'status': validation_result.get('status'),
                            'valid': validation_result.get('valid'),
                        }

                    # ì¢…í•© ê²€ì¦ ì‹¤íŒ¨ ê²½ê³ 
                    if validation_result.get('status') == 'failed':
                        logger.warning(
                            f"[SocialMonitoringHandler] Validation failed: "
                            f"Grade={validation_result.get('grade')}, "
                            f"Score={validation_result.get('score'):.2f}"
                        )
                        metadata['validation_warning'] = True

            # ê°œì„  ì œì•ˆ ì¶”ê°€
            if self.handler_config.log_filter_results and all_suggestions:
                logger.info(
                    f"[SocialMonitoringHandler] Suggestions: {', '.join(all_suggestions[:3])}"
                )
                metadata['improvement_suggestions'] = all_suggestions

            # === Sentiment Analysis ì ìš© ===
            if self.handler_config.sentiment_analysis_enabled and monitoring_data.get('items'):
                sentiment_result = self._apply_sentiment_analysis(monitoring_data['items'])
                filter_results['sentiment'] = sentiment_result

                if sentiment_result and self.handler_config.include_sentiment_details:
                    metadata['sentiment'] = sentiment_result

                    if self.handler_config.log_filter_results:
                        logger.info(
                            f"[SocialMonitoringHandler:Sentiment] "
                            f"Dominant={sentiment_result.get('dominant')}, "
                            f"Positive={sentiment_result.get('distribution_percent', {}).get('positive', 0)}%, "
                            f"Negative={sentiment_result.get('distribution_percent', {}).get('negative', 0)}%"
                        )

            # ëª¨ë‹ˆí„°ë§ ìš”ì•½ ì¶”ê°€
            if monitoring_data.get('items'):
                metadata['monitoring_summary'] = {
                    'total_items': len(monitoring_data['items']),
                    'total_engagement': monitoring_data.get('total_engagement', 0),
                    'platforms_covered': monitoring_data.get('platforms_covered', []),
                    'sentiment_summary': metadata.get('sentiment', {}),
                }

        except Exception as e:
            logger.error(f"[SocialMonitoringHandler] Error: {e}")
            response = "ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            metadata['error'] = str(e)

        # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
        processing_time = (datetime.now() - start_time).total_seconds() * 1000
        metadata['processing_time_ms'] = round(processing_time, 2)

        return {
            'response': response,
            'metadata': metadata,
            'filter_results': filter_results,
        }

    def _detect_monitoring_type(self, question: str) -> str:
        """ëª¨ë‹ˆí„°ë§ íƒ€ì… ê°ì§€"""
        question_lower = question.lower()

        if any(kw in question_lower for kw in ['ë©˜ì…˜', 'ì–¸ê¸‰', '@']):
            return 'mentions'
        elif any(kw in question_lower for kw in ['í•´ì‹œíƒœê·¸', '#', 'íƒœê·¸']):
            return 'hashtags'
        elif any(kw in question_lower for kw in ['ëŒ“ê¸€', 'ë°˜ì‘', 'í”¼ë“œë°±']):
            return 'engagement'
        else:
            return 'general'

    def _fetch_monitoring_data(self, question: str) -> Dict[str, Any]:
        """ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì¡°íšŒ - Contentì™€ Interaction ë…¸ë“œ ì‚¬ìš©"""
        try:
            from app.services.shared.neo4j import get_neo4j_client

            neo4j = get_neo4j_client()

            # Contentì™€ Interaction ë°ì´í„° ì¡°íšŒ
            query = """
            MATCH (c:Content)
            WHERE c.brand_id = $brand_id
            OPTIONAL MATCH (c)<-[:BELONGS_TO]-(i:Interaction)
            WITH c,
                 count(CASE WHEN i.type = 'like' THEN 1 END) as likes,
                 count(CASE WHEN i.type = 'comment' THEN 1 END) as comments,
                 collect(CASE WHEN i.type = 'comment' THEN {text: i.text, sentiment: i.sentiment} END)[0..5] as recent_comments
            RETURN c.id as id,
                   c.platform as platform,
                   c.caption as content,
                   c.content_type as content_type,
                   likes,
                   comments,
                   c.hashtags as hashtags,
                   recent_comments,
                   c.posted_at as posted_at
            ORDER BY c.posted_at DESC
            LIMIT $limit
            """

            items = neo4j.query(query, {
                'brand_id': self.brand_id,
                'limit': self.handler_config.max_results,
            }) or []

            # Interaction ê°ì • ë¶„ì„ ìš”ì•½
            sentiment_query = """
            MATCH (c:Content {brand_id: $brand_id})<-[:BELONGS_TO]-(i:Interaction)
            WHERE i.type = 'comment' AND i.sentiment IS NOT NULL
            RETURN i.sentiment as sentiment, count(*) as count
            """
            sentiment_data = neo4j.query(sentiment_query, {'brand_id': self.brand_id}) or []
            sentiment_summary = {row['sentiment']: row['count'] for row in sentiment_data}

            total_engagement = sum(
                (item.get('likes', 0) or 0) + (item.get('comments', 0) or 0)
                for item in items
            )
            platforms_covered = list(set(
                item.get('platform', 'unknown') for item in items if item.get('platform')
            ))

            return {
                'items': items,
                'total_engagement': total_engagement,
                'platforms_covered': platforms_covered,
                'sentiment_summary': sentiment_summary,
            }

        except Exception as e:
            logger.error(f"[SocialMonitoringHandler] Fetch error: {e}")
            return {'items': [], 'total_engagement': 0, 'platforms_covered': [], 'sentiment_summary': {}}

    def _format_monitoring_results(self, data: Dict[str, Any]) -> str:
        """ëª¨ë‹ˆí„°ë§ ê²°ê³¼ í¬ë§·íŒ…"""
        items = data.get('items', [])
        total_engagement = data.get('total_engagement', 0)
        platforms = data.get('platforms_covered', [])
        sentiment_summary = data.get('sentiment_summary', {})

        lines = ["ğŸ“¡ **ì†Œì…œ ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸**\n"]

        lines.append("**ğŸ“Š ìš”ì•½**")
        lines.append(f"- ì½˜í…ì¸  ìˆ˜: {len(items)}ê°œ")
        lines.append(f"- ì´ ì¸ê²Œì´ì§€ë¨¼íŠ¸: {total_engagement:,}")
        lines.append(f"- í”Œë«í¼: {', '.join(platforms) if platforms else 'N/A'}")

        # ê°ì • ë¶„ì„ ìš”ì•½
        if sentiment_summary:
            positive = sentiment_summary.get('positive', 0)
            neutral = sentiment_summary.get('neutral', 0)
            negative = sentiment_summary.get('negative', 0)
            total_sentiment = positive + neutral + negative
            if total_sentiment > 0:
                lines.append(f"- ëŒ“ê¸€ ê°ì •: ğŸ˜Š {positive}ê°œ ({positive*100//total_sentiment}%) | ğŸ˜ {neutral}ê°œ | ğŸ˜Ÿ {negative}ê°œ")
        lines.append("")

        lines.append("**ğŸ“ ìµœê·¼ ì½˜í…ì¸ **")
        for i, item in enumerate(items[:5], 1):
            platform = item.get('platform', 'unknown')
            content = (item.get('content', '') or '')[:50]
            likes = item.get('likes', 0) or 0
            comments = item.get('comments', 0) or 0
            content_type = item.get('content_type', '')

            platform_emoji = {
                'instagram': 'ğŸ“¸',
                'twitter': 'ğŸ¦',
                'youtube': 'ğŸ“º',
                'tiktok': 'ğŸµ',
            }.get(platform, 'ğŸ“±')

            type_tag = f"[{content_type}] " if content_type else ""
            lines.append(f"{i}. {platform_emoji} {type_tag}{content}...")
            lines.append(f"   â¤ï¸ {likes:,} | ğŸ’¬ {comments:,}")

            # ìµœê·¼ ëŒ“ê¸€ í‘œì‹œ
            recent_comments = item.get('recent_comments', [])
            if recent_comments:
                for comment in recent_comments[:2]:
                    if comment and comment.get('text'):
                        sentiment_emoji = {'positive': 'ğŸ˜Š', 'neutral': 'ğŸ˜', 'negative': 'ğŸ˜Ÿ'}.get(comment.get('sentiment', ''), 'ğŸ’¬')
                        comment_text = (comment.get('text', '') or '')[:30]
                        lines.append(f"      {sentiment_emoji} \"{comment_text}...\"")

        lines.append("")
        lines.append("ë” ìì„¸í•œ ë¶„ì„ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”!")

        return "\n".join(lines)

    def _generate_no_data_response(self) -> str:
        """ë°ì´í„° ì—†ì„ ë•Œ ì‘ë‹µ"""
        return (
            "í˜„ì¬ ëª¨ë‹ˆí„°ë§í•  ì†Œì…œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n\n"
            "ë‹¤ìŒ ê¸°ëŠ¥ì„ ì„¤ì •í•˜ì‹œë©´ ëª¨ë‹ˆí„°ë§ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n"
            "- SNS ê³„ì • ì—°ë™\n"
            "- í‚¤ì›Œë“œ/í•´ì‹œíƒœê·¸ ì„¤ì •\n"
            "- ì•Œë¦¼ ì„¤ì •"
        )

    def _apply_quality_filter(
        self,
        response: str,
        context: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """í’ˆì§ˆ í•„í„° ì ìš©"""
        try:
            result: QualityResult = self.quality_filter.validate(response, context)

            if self.handler_config.log_filter_results:
                logger.info(
                    f"[SocialMonitoringHandler:Quality] "
                    f"Score={result.score:.2f}, Level={result.level.value}"
                )

            return {
                'score': result.score,
                'level': result.level.value,
                'valid': result.valid,
                'suggestions': result.suggestions,
            }

        except Exception as e:
            logger.error(f"[SocialMonitoringHandler:Quality] Error: {e}")
            return None

    def _apply_trust_filter(
        self,
        response: str,
        question: str,
        context: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """ì‹ ë¢°ì„± í•„í„° ì ìš©"""
        try:
            trust_context = {
                **context,
                'question': question,
            }

            result: TrustResult = self.trust_filter.validate(response, trust_context)

            if self.handler_config.log_filter_results:
                logger.info(
                    f"[SocialMonitoringHandler:Trust] "
                    f"Score={result.score:.2f}, "
                    f"HallucinationRisk={result.hallucination_risk:.2f}"
                )

            return {
                'score': result.score,
                'level': result.level.value,
                'hallucination_risk': result.hallucination_risk,
                'valid': result.valid,
            }

        except Exception as e:
            logger.error(f"[SocialMonitoringHandler:Trust] Error: {e}")
            return None

    def _apply_relevance_filter(
        self,
        response: str,
        question: str,
        context: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        ê´€ë ¨ì„± í•„í„° ì ìš©

        Args:
            response: ìƒì„±ëœ ì‘ë‹µ
            question: ì›ë³¸ ì§ˆë¬¸
            context: ì»¨í…ìŠ¤íŠ¸

        Returns:
            ê´€ë ¨ì„± ê²€ì¦ ê²°ê³¼
        """
        try:
            relevance_context = {
                **context,
                'question': question,
            }

            result: RelevanceResult = self.relevance_filter.validate(response, relevance_context)

            if self.handler_config.log_filter_results:
                logger.info(
                    f"[SocialMonitoringHandler:Relevance] "
                    f"Score={result.score:.2f}, "
                    f"Level={result.level.value}, "
                    f"ResponseType={result.response_type.value}, "
                    f"Valid={result.valid}"
                )

                if result.issues:
                    for issue in result.issues[:3]:
                        logger.warning(
                            f"[SocialMonitoringHandler:Relevance] Issue: "
                            f"[{issue.relevance_type.value}] {issue.message}"
                        )

            return {
                'score': result.score,
                'level': result.level.value,
                'response_type': result.response_type.value,
                'valid': result.valid,
                'issues': [
                    {
                        'type': issue.relevance_type.value,
                        'severity': issue.severity.value,
                        'message': issue.message,
                    }
                    for issue in result.issues
                ],
                'scores': {
                    rtype.value: rs.score
                    for rtype, rs in result.scores.items()
                } if hasattr(result, 'scores') and result.scores else {},
            }

        except Exception as e:
            logger.error(f"[SocialMonitoringHandler:Relevance] Error: {e}")
            return None

    def _apply_validation_filter(
        self,
        response: str,
        question: str,
        context: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        ì¢…í•© ê²€ì¦ í•„í„° ì ìš©

        Args:
            response: ìƒì„±ëœ ì‘ë‹µ
            question: ì›ë³¸ ì§ˆë¬¸
            context: ì»¨í…ìŠ¤íŠ¸

        Returns:
            ì¢…í•© ê²€ì¦ ê²°ê³¼
        """
        try:
            validation_context = {
                **context,
                'question': question,
            }

            result: ValidationResult = self.validation_filter.validate(response, validation_context)

            if self.handler_config.log_filter_results:
                logger.info(
                    f"[SocialMonitoringHandler:Validation] "
                    f"Score={result.score:.2f}, "
                    f"Grade={result.grade.value}, "
                    f"Status={result.status.value}, "
                    f"Valid={result.valid}"
                )

                if result.all_issues:
                    for issue in result.all_issues[:3]:
                        logger.warning(f"[SocialMonitoringHandler:Validation] Issue: {issue}")

            return {
                'score': result.score,
                'grade': result.grade.value,
                'status': result.status.value,
                'valid': result.valid,
                'summary': {
                    'total_issues': result.summary.total_issues,
                    'total_warnings': result.summary.total_warnings,
                    'passed_filters': result.summary.passed_filters,
                    'failed_filters': result.summary.failed_filters,
                },
                'issues': result.all_issues,
                'warnings': result.all_warnings,
                'suggestions': result.suggestions,
            }

        except Exception as e:
            logger.error(f"[SocialMonitoringHandler:Validation] Error: {e}")
            return None

    def _apply_sentiment_analysis(
        self,
        items: List[Dict[str, Any]]
    ) -> Optional[Dict[str, Any]]:
        """
        ê°ì • ë¶„ì„ ì ìš©

        Args:
            items: ëª¨ë‹ˆí„°ë§ í•­ëª© ë¦¬ìŠ¤íŠ¸

        Returns:
            ê°ì • ë¶„ì„ ê²°ê³¼ ìš”ì•½
        """
        try:
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            texts = [
                item.get('content', '') or item.get('text', '')
                for item in items
                if item.get('content') or item.get('text')
            ]

            if not texts:
                return None

            # ë°°ì¹˜ ë¶„ì„
            results: List[SentimentResult] = self.sentiment_analyzer.analyze_batch(texts)

            # ìš”ì•½ ìƒì„±
            summary = self.sentiment_analyzer.get_summary(results)

            # ê°œë³„ ê²°ê³¼ë„ í¬í•¨
            individual_results = [
                {
                    'label': r.label.value,
                    'confidence': round(r.confidence, 3),
                    'keywords': r.keywords_found[:5],  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ
                }
                for r in results[:10]  # ìƒìœ„ 10ê°œë§Œ
            ]

            return {
                **summary,
                'individual_results': individual_results,
                'dominant': summary.get('dominant_sentiment'),
            }

        except Exception as e:
            logger.error(f"[SocialMonitoringHandler:Sentiment] Error: {e}")
            return None

    def analyze_content_sentiment(self, content: str) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ì½˜í…ì¸  ê°ì • ë¶„ì„ (ì™¸ë¶€ í˜¸ì¶œìš©)

        Args:
            content: ë¶„ì„í•  í…ìŠ¤íŠ¸

        Returns:
            ê°ì • ë¶„ì„ ê²°ê³¼
        """
        try:
            result = self.sentiment_analyzer.analyze(content)
            return result.to_dict()
        except Exception as e:
            logger.error(f"[SocialMonitoringHandler:Sentiment] Single analysis error: {e}")
            return {'label': 'neutral', 'confidence': 0, 'error': str(e)}

    def get_filter_stats(self) -> Dict[str, Any]:
        """í•„í„° í†µê³„ ë°˜í™˜"""
        return {
            'quality_filter_enabled': self.handler_config.quality_filter_enabled,
            'trust_filter_enabled': self.handler_config.trust_filter_enabled,
            'relevance_filter_enabled': self.handler_config.relevance_filter_enabled,
            'validation_filter_enabled': self.handler_config.validation_filter_enabled,
            'sentiment_analysis_enabled': self.handler_config.sentiment_analysis_enabled,
            'min_quality_score': self.handler_config.min_quality_score,
            'min_trust_score': self.handler_config.min_trust_score,
            'min_relevance_score': self.handler_config.min_relevance_score,
            'validation_pass_threshold': self.handler_config.validation_pass_threshold,
            'sentiment_analysis_mode': self.handler_config.sentiment_analysis_mode,
            'platforms': self.handler_config.platforms,
            'max_results': self.handler_config.max_results,
        }
