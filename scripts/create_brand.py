### **scripts/create_brand.py**
#!/usr/bin/env python3
"""
Brand Creation Script
ìƒˆë¡œìš´ ë¸Œëœë“œ ì„¤ì • ìƒì„±
"""

import typer
import yaml
from pathlib import Path
from rich.console import Console
from rich.prompt import Prompt, Confirm
from typing import Optional

app = typer.Typer()
console = Console()


@app.command()
def create(
    brand_id: Optional[str] = None,
    interactive: bool = True
):
    """
    ìƒˆë¡œìš´ ë¸Œëœë“œ ìƒì„±
    
    Args:
        brand_id: ë¸Œëœë“œ ID
        interactive: ëŒ€í™”í˜• ëª¨ë“œ
    """
    console.print("\nğŸ¨ [bold cyan]ONTIX Universal - Brand Creator[/bold cyan]\n")
    
    # ë¸Œëœë“œ ID ì…ë ¥
    if not brand_id:
        brand_id = Prompt.ask("ë¸Œëœë“œ IDë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ë¬¸ ì†Œë¬¸ì, í•˜ì´í”ˆ ê°€ëŠ¥)")
    
    brand_id = brand_id.lower().strip()
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    config_path = Path(f"configs/brands/{brand_id}.yaml")
    
    if config_path.exists():
        console.print(f"[red]âŒ ë¸Œëœë“œê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {brand_id}[/red]")
        
        if not Confirm.ask("ë®ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ?"):
            console.print("[yellow]ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.[/yellow]")
            return
    
    # ëŒ€í™”í˜• ì…ë ¥
    if interactive:
        brand_data = _interactive_input(brand_id)
    else:
        brand_data = _create_minimal_config(brand_id)
    
    # YAML ì €ì¥
    config_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(brand_data, f, allow_unicode=True, sort_keys=False)
    
    console.print(f"\n[green]âœ… ë¸Œëœë“œ ìƒì„± ì™„ë£Œ: {config_path}[/green]")
    
    # í”„ë¡¬í”„íŠ¸ í´ë” ìƒì„± ì—¬ë¶€
    if Confirm.ask("\në¸Œëœë“œ ì „ìš© í”„ë¡¬í”„íŠ¸ í´ë”ë¥¼ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"):
        _create_prompt_folder(brand_id)
    
    console.print("\n[bold green]ğŸ‰ ì™„ë£Œ![/bold green]")
    console.print(f"\në‹¤ìŒ ë‹¨ê³„:")
    console.print(f"1. configs/brands/{brand_id}.yaml ì„¤ì • í™•ì¸")
    console.print(f"2. python scripts/validate_config.py {brand_id}")
    console.print(f"3. python scripts/sync_brand.py {brand_id}")


def _interactive_input(brand_id: str) -> dict:
    """ëŒ€í™”í˜• ì…ë ¥"""
    console.print("\n[cyan]ë¸Œëœë“œ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:[/cyan]\n")
    
    brand_name = Prompt.ask("ë¸Œëœë“œ ì´ë¦„", default=brand_id.upper())
    description = Prompt.ask("ë¸Œëœë“œ ì„¤ëª…")
    industry = Prompt.ask("ì‚°ì—… ë¶„ë¥˜", default="General")
    
    # ê¸°ëŠ¥ ì„ íƒ
    console.print("\n[cyan]í™œì„±í™”í•  ê¸°ëŠ¥ì„ ì„ íƒí•˜ì„¸ìš”:[/cyan]")
    
    all_features = [
        "conversational",
        "factual",
        "product_recommendation",
        "analytics",
        "advisor",
        "content_generation",
        "social_monitoring",
        "onboarding"
    ]
    
    features = []
    
    for feature in all_features:
        if Confirm.ask(f"  {feature}", default=feature in ["conversational", "factual"]):
            features.append(feature)
    
    # ì„¤ì • ìƒì„±
    config = {
        'brand': {
            'id': brand_id,
            'name': brand_name,
            'description': description,
            'industry': industry
        },
        'features': features,
        'neo4j': {
            'brand_id': brand_id,
            'namespaces': [brand_id],
            'vector_index': 'ontix_global_concept_index'
        },
        'retrieval': _create_retrieval_config(features),
        'generation': _create_generation_config(features)
    }
    
    return config


def _create_minimal_config(brand_id: str) -> dict:
    """ìµœì†Œ ì„¤ì • ìƒì„±"""
    return {
        'brand': {
            'id': brand_id,
            'name': brand_id.upper(),
            'description': f'{brand_id} brand',
            'industry': 'General'
        },
        'features': ['conversational', 'factual'],
        'neo4j': {
            'brand_id': brand_id,
            'namespaces': [brand_id],
            'vector_index': 'ontix_global_concept_index'
        },
        'retrieval': {
            'factual': {
                'retrievers': ['graph', 'vector'],
                'max_results': 10
            },
            'conversational': {
                'retrievers': ['graph'],
                'max_results': 5
            }
        },
        'generation': {
            'factual': {
                'type': 'factual',
                'fallback_prompt': 'shared/factual/base.txt',
                'model': 'mini',
                'temperature': 0
            },
            'conversational': {
                'type': 'conversational',
                'fallback_prompt': 'shared/conversational/base.txt',
                'model': 'full',
                'temperature': 0.8
            }
        }
    }


def _create_retrieval_config(features: list) -> dict:
    """Retrieval ì„¤ì • ìƒì„±"""
    config = {}
    
    retrieval_templates = {
        'factual': {
            'retrievers': ['graph', 'vector'],
            'max_results': 10
        },
        'product_recommendation': {
            'retrievers': ['product', 'vector'],
            'max_results': 20
        },
        'analytics': {
            'retrievers': ['stats', 'graph'],
            'max_results': 50
        },
        'advisor': {
            'retrievers': ['vector', 'graph'],
            'max_results': 10
        },
        'conversational': {
            'retrievers': ['graph'],
            'max_results': 5
        }
    }
    
    for feature in features:
        if feature in retrieval_templates:
            config[feature] = retrieval_templates[feature]
    
    return config


def _create_generation_config(features: list) -> dict:
    """Generation ì„¤ì • ìƒì„±"""
    config = {}
    
    generation_templates = {
        'factual': {
            'type': 'factual',
            'fallback_prompt': 'shared/factual/base.txt',
            'model': 'mini',
            'temperature': 0
        },
        'product_recommendation': {
            'type': 'recommendation',
            'fallback_prompt': 'shared/factual/product.txt',
            'model': 'full',
            'temperature': 0.7
        },
        'analytics': {
            'type': 'insight',
            'fallback_prompt': 'shared/insight/base.txt',
            'model': 'full',
            'temperature': 0.7
        },
        'advisor': {
            'type': 'insight',
            'fallback_prompt': 'shared/insight/advisor.txt',
            'model': 'full',
            'temperature': 0.7
        },
        'conversational': {
            'type': 'conversational',
            'fallback_prompt': 'shared/conversational/base.txt',
            'model': 'full',
            'temperature': 0.8
        }
    }
    
    for feature in features:
        if feature in generation_templates:
            config[feature] = generation_templates[feature]
    
    return config


def _create_prompt_folder(brand_id: str):
    """ë¸Œëœë“œ í”„ë¡¬í”„íŠ¸ í´ë” ìƒì„±"""
    prompt_dir = Path(f"prompts/{brand_id}")
    prompt_dir.mkdir(parents=True, exist_ok=True)
    
    # README ìƒì„±
    readme = prompt_dir / "README.md"
    readme.write_text(f"""# {brand_id.upper()} Custom Prompts

ë¸Œëœë“œ ì „ìš© í”„ë¡¬í”„íŠ¸ë¥¼ ì´ê³³ì— ì¶”ê°€í•˜ì„¸ìš”.

## íŒŒì¼ ëª…ëª… ê·œì¹™

- `factual_[subtype].txt` - íŒ©íŠ¸ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸
- `insight_[subtype].txt` - ì¸ì‚¬ì´íŠ¸ í”„ë¡¬í”„íŠ¸
- `conversational_[subtype].txt` - ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸

## ì˜ˆì‹œ

```
prompts/{brand_id}/
â”œâ”€â”€ factual_product.txt
â”œâ”€â”€ insight_advisor.txt
â””â”€â”€ conversational_base.txt
```

## ì„¤ì • ì—°ê²°

configs/brands/{brand_id}.yamlì—ì„œ ì—°ê²°:

```yaml
generation:
  product_recommendation:
    prompt: {brand_id}/factual_product.txt
    fallback_prompt: shared/factual/product.txt
```
""")
    
    console.print(f"[green]âœ… í”„ë¡¬í”„íŠ¸ í´ë” ìƒì„±: {prompt_dir}[/green]")


if __name__ == "__main__":
    app()
